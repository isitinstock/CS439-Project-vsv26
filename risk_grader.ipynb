{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca748e6a-2a49-4ac8-b5f2-91ceb409f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading raw events and smoothed probabilities...\n",
      "2. Calculating daily risk and assigning grades for all customers...\n",
      "\n",
      "Risk grading complete. Daily risk grades saved to daily_risk_grades.csv\n",
      "Total daily risk records generated: 27917\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# take the smoothed ngram scores and event data to generate grades\n",
    "RAW_EVENTS_PATH = 'raw_events.csv'\n",
    "SMOOTHED_PROBS_PATH = 'smoothed_probabilities.csv'\n",
    "OUTPUT_PATH = 'daily_risk_grades.csv'\n",
    "EVENT_WINDOW_DAYS = 30\n",
    "MAX_N_GRAM = 3\n",
    "\n",
    "# Define the grading scale based on probability\n",
    "# Arbitrary grading scale\n",
    "# If i wanted to improve it, I could add an extra normalization step\n",
    "GRADING_SCALE = {\n",
    "    'A': (0.00, 0.05),  # Very Low Risk\n",
    "    'B': (0.05, 0.10),  # Low Risk\n",
    "    'C': (0.10, 0.15),  # Moderate Risk (around the prior mean)\n",
    "    'D': (0.15, 0.25),  # High Risk\n",
    "    'F': (0.25, 1.00)   # Very High Risk\n",
    "}\n",
    "\n",
    "def get_grade(probability):\n",
    "    \"\"\"Assigns a letter grade based on the churn probability.\"\"\"\n",
    "    for grade, (lower, upper) in GRADING_SCALE.items():\n",
    "        if lower <= probability < upper:\n",
    "            return grade\n",
    "    return 'F' # fallback\n",
    "\n",
    "def get_ngrams(sequence, max_n):\n",
    "    \"\"\"Generates all n-grams (up to 3) from a sequence\"\"\"\n",
    "    ngrams = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        if len(sequence) >= n:\n",
    "            ngrams.append(tuple(sequence[-n:]))\n",
    "    return ngrams\n",
    "\n",
    "def process_customer_risk(customer_df, prob_map):\n",
    "    \"\"\"Calculates the daily risk per customer. This is done by finding \n",
    "    the highest risk ngram per window and using that to assign a grade. This is a simple way,\n",
    "    but not the best. The best would be to account for ALL ngrams within the window.\"\"\"\n",
    "    customer_df = customer_df.sort_values(by='event_date')\n",
    "    customer_df['event_date'] = pd.to_datetime(customer_df['event_date'])\n",
    "    \n",
    "    daily_risk = []\n",
    "    \n",
    "    for i in range(len(customer_df)):\n",
    "        current_event = customer_df.iloc[i]\n",
    "        current_date = current_event['event_date']\n",
    "        \n",
    "        # Define the 30-day lookback window\n",
    "        window_start_date = current_date - pd.Timedelta(days=EVENT_WINDOW_DAYS)\n",
    "        \n",
    "        # Filter events within the window (including the current event)\n",
    "        window_events = customer_df[\n",
    "            (customer_df['event_date'] > window_start_date) & \n",
    "            (customer_df['event_date'] <= current_date)\n",
    "        ]\n",
    "        \n",
    "        event_sequence = window_events['event_code'].tolist()\n",
    "        \n",
    "        # Extract n-grams from the end of the sequence (most recent events)\n",
    "        ngrams = get_ngrams(event_sequence, MAX_N_GRAM)\n",
    "        \n",
    "        # Find the highest risk n-gram (the most predictive one)\n",
    "        max_prob = 0.0\n",
    "        best_ngram = None\n",
    "        \n",
    "        for ngram in ngrams:\n",
    "            ngram_key = ' '.join(ngram)\n",
    "            prob = prob_map.get(ngram_key, 0.15) # Default to prior mean if ngram not seen\n",
    "            \n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                best_ngram = ngram_key\n",
    "                \n",
    "        # Assign the risk score and grade\n",
    "        risk_grade = get_grade(max_prob)\n",
    "        \n",
    "        daily_risk.append({\n",
    "            'customer_id': current_event['customer_id'],\n",
    "            'event_date': current_date,\n",
    "            'churn_probability': max_prob,\n",
    "            'risk_grade': risk_grade,\n",
    "            'driving_ngram': best_ngram,\n",
    "            'actual_churn_in_90_days': current_event['churn_in_90_days']\n",
    "        })\n",
    "            \n",
    "    return daily_risk\n",
    "\n",
    "# MAIN\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"1. Reading raw events and smoothed probabilities...\")\n",
    "    try:\n",
    "        raw_events_df = pd.read_csv(RAW_EVENTS_PATH)\n",
    "        smoothed_df = pd.read_csv(SMOOTHED_PROBS_PATH)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Run the previous steps\")\n",
    "        exit()\n",
    "\n",
    "    # Create a map from n-gram string to smoothed probability for fast lookup\n",
    "    prob_map = smoothed_df.set_index('ngram')['smoothed_probability'].to_dict()\n",
    "\n",
    "    print(\"2. Calculating daily risk and assigning grades for all customers...\")\n",
    "    all_daily_risk = []\n",
    "    \n",
    "    customer_groups = raw_events_df.groupby('customer_id')\n",
    "    \n",
    "    #add the daily risk for each customer\n",
    "    for cust_id, group in customer_groups:\n",
    "        all_daily_risk.extend(process_customer_risk(group, prob_map))\n",
    "        \n",
    "    daily_risk_df = pd.DataFrame(all_daily_risk)\n",
    "    \n",
    "    # sortings\n",
    "    daily_risk_df = daily_risk_df.sort_values(by=['customer_id', 'event_date']).reset_index(drop=True)\n",
    "    \n",
    "    # Save the final daily risk grades file\n",
    "    daily_risk_df.to_csv(OUTPUT_PATH, index=False)\n",
    "    \n",
    "    print(f\"\\nRisk grading complete. Daily risk grades saved to {OUTPUT_PATH}\")\n",
    "    print(f\"Total daily risk records generated: {len(daily_risk_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fc2b5-c280-4bad-b7ce-52b0908c90db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
